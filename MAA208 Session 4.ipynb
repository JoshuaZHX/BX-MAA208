{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Iteration method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this class we consider a numerical method used to compute the eigenvalues and the eigenvectors of a matrix. \n",
    "The method for finding eigenvectors and eigenvalues is called **Power Iteration**, or von Mises Iteration after Richard von Mises - famous german mathematician (1883-1953) known for his results in mechanics, in statistics or in probability theory. \n",
    "\n",
    "Power Iteration method works under some assumptions and may fail if they are not satisfied. So in this class you are proposed to investigate theoretically and numerically these assumptions.\n",
    "    \n",
    "**Remark about the applications**: The algorithm is well-known to be used for computing ***PageRank*** (interplay between \"Larry Page\", the co-founder of Google. Inc and \"a web page\"). PageRank is a map that associates a rank, i.e. just a scalar value, to websites such that \"more important\" websites get a higher rank and \"less important\" the lower one.\n",
    "One can read about PageRank and an associated eigenvalue problem for matrices e.g. in: https://en.m.wikipedia.org/wiki/PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principle of the method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Refresher:**\n",
    "<p> We consider a diagonalizable matrix $A = PDP^{-1}$, where $D$ is diagonal and $P$ is invertible. There exists a basis of $\\mathbb{R}^N$ composed of eigenvectors $(V^1, \\, \\dots, V^N)$ of $A$ associated to the eigenvalues $(\\lambda_1, \\dots, \\lambda_N)$. Especially, decomposing any vector $V$ in this basis, one writes\n",
    "\\begin{align*}\n",
    " V = \\sum\\limits_{i=1}^N \\alpha_i V^i \\qquad \\Rightarrow \\quad AV = \\sum\\limits_{i=1}^N \\alpha_i \\lambda_i V^i, \n",
    "\\end{align*}\n",
    "where $(\\alpha_1, \\dots, \\alpha_N) \\in\\mathbb{R}^N$ are the components of $V$ in the basis of eigenvectors of $A$. \n",
    "<p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construction of the algorithm:**\n",
    "\n",
    "This algorithm aims to compute ***the maximal eigenvalue and an associated eigenvector***.\n",
    "\n",
    "We consider a diagonalizable matrix $A = P D P^{-1} \\in\\mathbb{R}^{N\\times N}$  with non-zero eigenvalues that we order such that $|\\lambda_1| \\ge |\\lambda_2| \\ge \\dots \\ge |\\lambda_N| > 0$. \n",
    "\n",
    "Define the sequence $(U^k)_{k\\in\\mathbb{N}}$ iteratively by \n",
    "\\begin{equation}\n",
    "U^{k+1} = f(U^k) = \\frac{A U^k}{\\|AU^k\\|}, \\text{ for }k \\geq 0, \\text{ where } U_0 \\text{ is an initial vector.}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the power iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) a) Implement a function computing the sequence $U^k$. \n",
    "\n",
    "**Indications:** Your code should: <ul>\n",
    "<li> \n",
    "    <b>stop</b> at iteration $k$ if <ul>\n",
    "<li> $\\|U^{k}-U^{k-1}\\| \\le \\epsilon_{\\max}$,</li>\n",
    "<li> $k>k_{\\max}$,</li>\n",
    "    </ul>\n",
    "where $\\epsilon_{\\max}$ and $k_{\\max}$ are given as input of the function.\n",
    "<li> take for <b>input</b>: the matrix $A$, the initial vector $U^0$, the parameters $\\epsilon_{max}$ and $k_{\\max}$.</li>\n",
    "<li> <b>return</b>: the final solution $U^k$ and $r = (AU^k)^T U^k$</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PowerIteration(A, U0, err_max, k_max):\n",
    "    U = np.copy(U0)\n",
    "    r = 0.\n",
    "    return U, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Test it with $A = \\left(\\begin{array}{cccc} 10 & 9 & -11 & -4 \\\\ 12 & 13 & -7 & -14 \\\\ 12 & 19 & -13 & -14 \\\\ 12 & 5 & -7 & -6\\end{array}\\right)$, $\\epsilon_{\\max} = 10^{-8}$ and $k_{\\max} = 50$ and $U^0 = (1, 1, 1, 1)^T$. \n",
    "\n",
    "What value of $(U^k, r)$ do you obtain? Check if $U^k$ is an eigenvector of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Test it again with the same parameters with an initial $U^0 = (1,4,2,4)^T$.\n",
    "\n",
    "What value of $(U^k,r)$ do you obtain? Check if $U^k$ is an eigenvector of $A$.\n",
    "\n",
    "In the next section, we study the convergence of the algorithm for different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence of the method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Assume that $V$ is an eigenvector of $A$ such that $\\|V\\|^2 = V^T V = 1$. Write the eigenvalue $\\lambda$ associated to $V$ as a function of $A$ and $V$ using only matrix (and vector) products. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Prove that the sequence of the power iteration algorithm satisfies $U^{k+1} = \\frac{A^{k+1} U^0}{ \\|A^{k+1} U^0\\|}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) In this question, we aim to rewrite $U^{k+1}$ under the form $$U^{k+1} = \\frac{\\alpha_1}{|\\alpha_1|} \\left(\\frac{\\lambda_1}{|\\lambda_1|}\\right)^{k+1} \\left( V^1 + \\text{error}_k \\right), $$\n",
    "such that $\\text{error}_k$ tends to $0_{\\mathbb{R}^N}$ when $k$ tends to infinity (to prove in the next question).\n",
    "Let us decompose the intial vector \\begin{equation*} U^0 = \\sum\\limits_{i=1}^N \\alpha_i V^i\\end{equation*} where the vectors $V^i$ is an eigenvector of $A$ of norm $\\|V^i\\| = 1$ associated to the $i$-th eigenvalue $\\lambda_i$ of $A$. \n",
    "\n",
    "a) Decomposing the vector $A^{k+1} U^0 = \\sum\\limits_{i=1}^N \\beta_i V^i$, express $\\beta_i$ as a function of the $\\alpha_i$ and $\\lambda_i$. \n",
    "\n",
    "b) Factorize the vector $A^{k+1} U^{0}$ by the scalar $\\alpha_1 \\lambda_1^{k+1}$\n",
    "\n",
    "c) Factorize the scalar $\\|A^{k+1} U^{0}\\|$ by the scalar $|\\alpha_1| |\\lambda_1|^{k+1}$. \n",
    "\n",
    "d) Then factorize the vector $U^{k+1}$ by the scalar $\\frac{\\alpha_1}{|\\alpha_1|} \\left(\\frac{\\lambda_1}{|\\lambda_1|}\\right)^{k+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "a)\n",
    "\n",
    "b)\n",
    "\n",
    "c)\n",
    "\n",
    "d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) We study now the convergence of the sequence $U^k$: \n",
    "\n",
    "a) Assuming that $\\lambda_1>0$, conclude on the convergence of the sequence $(U^k)_{k\\in\\mathbb{N}}$. What happens if $\\lambda_1<0$?\n",
    "\n",
    "b) What hypothesis on the intialization $U^0$ is crucial for this method to converge to the desired vector $V$ associated to the largest eigenvalue in norm ? \n",
    "\n",
    "c) Give a condition on $U^0$ fo the power iteration algorithm <b>NOT</b> to converge to the eigenvector $V^1$ associated to the largest eigenvalue in norm.\n",
    "\n",
    "d) Explain the difference in the results obtained in the last section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "a)\n",
    "\n",
    "b)\n",
    "\n",
    "c)\n",
    "\n",
    "d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing all eigenvectors and eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Hypothesis: </b> We assume now that $A$ is symmetric. Such real symmetric matrices are diagonalizable in an orthonormal bases. This means that there exists an orthogonal matrix $Q$ (orthogonal matrices satisfy $Q^{-1} = Q^T$) such that $A = Q D Q^{-1} = Q D Q^T$. \n",
    "\n",
    "Let $U^k$ be the vector obtained at the end of the previous algorithm, and assume that it is exactly the eigenvector $U^k = V^1$ associated to the largest eigenvalue $\\lambda_1$ in norm. \n",
    "\n",
    "1) Construct a matrix $B$ such that: \n",
    "- $B$ has the same eigenvectors $V^i$ as $A$\n",
    "- $B$ has the same eigenvalue $\\lambda_i$ associated to $V^i$ except $\\lambda_1=0$, i.e. the eigenvalue associated to $V^1$ is zero. \n",
    "\n",
    "Write $B$ as a function of $A$, $\\lambda_1$ and $V^1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Deduce a method to compute a second eigenvector and eigenvalue. And a third..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) a) Implement an algorithm computing all the eigenvectors and eigenvalues. \n",
    "\n",
    "Your function should:\n",
    "- take for <b>input</b> the matrix $A$ and the stopping parameters $\\varepsilon_{max}$, and $k_{max}$\n",
    "- <b>return</b> the matrix $P$ composed of the eigenvectors of $A$ and a vector $\\Lambda$ of the associated eigenvalues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PowerIterationDecomposition(A, err_max, k_max):\n",
    "    N = len(A)\n",
    "    P = np.eye(N)\n",
    "    L = np.array(N)\n",
    "    return P, L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Test it with the matrix $A = \\left( \\begin{array}{cccc} 4 & 0 & 10 & 0 \\\\ 0 & 10 & 0 & 18 \\\\ 10 & 0 & 18 & 0 \\\\ 0 & 18 & 0 & 34 \\end{array}\\right)$, with $\\epsilon_{\\max} = 10^{-8}$ and $k_{\\max} = 20$. Choose an appropriate $U_0$ for every power iteration algorithm. Check if all the columns of $P$ are eigenvectors of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
